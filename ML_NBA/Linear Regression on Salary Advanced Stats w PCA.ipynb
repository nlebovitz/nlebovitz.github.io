{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c50aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df4fa6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"player_salaries_2014_2018_test.xlsx\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caa4677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>...</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Register Value</th>\n",
       "      <th>Salary in $</th>\n",
       "      <th>Season End</th>\n",
       "      <th>Full Team Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>OKC</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>1197</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.541</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>71</td>\n",
       "      <td>203</td>\n",
       "      <td>265</td>\n",
       "      <td>10096</td>\n",
       "      <td>2184960</td>\n",
       "      <td>2015</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Alexis Ajinca</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>NOH</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>951</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.589</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>328</td>\n",
       "      <td>9640</td>\n",
       "      <td>981084</td>\n",
       "      <td>2015</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>NYK</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.620</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>92</td>\n",
       "      <td>9721</td>\n",
       "      <td>981084</td>\n",
       "      <td>2015</td>\n",
       "      <td>New York Knicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>PF</td>\n",
       "      <td>28</td>\n",
       "      <td>POR</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>2498</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.507</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "      <td>123</td>\n",
       "      <td>147</td>\n",
       "      <td>1603</td>\n",
       "      <td>9941</td>\n",
       "      <td>16006000</td>\n",
       "      <td>2015</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Lavoy Allen</td>\n",
       "      <td>PF</td>\n",
       "      <td>24</td>\n",
       "      <td>IND</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.521</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>9947</td>\n",
       "      <td>948163</td>\n",
       "      <td>2015</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joe Young</td>\n",
       "      <td>PG</td>\n",
       "      <td>24</td>\n",
       "      <td>IND</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.433</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>11566</td>\n",
       "      <td>1471382</td>\n",
       "      <td>2018</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>28</td>\n",
       "      <td>IND</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>2237</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.562</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>135</td>\n",
       "      <td>814</td>\n",
       "      <td>11784</td>\n",
       "      <td>14796348</td>\n",
       "      <td>2018</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2017</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>PF</td>\n",
       "      <td>24</td>\n",
       "      <td>CHA</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>1725</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.604</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>189</td>\n",
       "      <td>639</td>\n",
       "      <td>11404</td>\n",
       "      <td>12584270</td>\n",
       "      <td>2018</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul Zipser</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>CHI</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>843</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.503</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>240</td>\n",
       "      <td>11721</td>\n",
       "      <td>1312611</td>\n",
       "      <td>2018</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>19</td>\n",
       "      <td>LAL</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>609</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>284</td>\n",
       "      <td>11520</td>\n",
       "      <td>1312611</td>\n",
       "      <td>2018</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year             Player Pos  Age   Tm   G  GS    MP   PER    TS%  ...  \\\n",
       "0    2014       Steven Adams   C   20  OKC  81  20  1197  11.2  0.541  ...   \n",
       "1    2014      Alexis Ajinca   C   25  NOH  56  30   951  14.6  0.589  ...   \n",
       "2    2014       Cole Aldrich   C   25  NYK  46   2   330  19.1  0.620  ...   \n",
       "3    2014  LaMarcus Aldridge  PF   28  POR  69  69  2498  21.8  0.507  ...   \n",
       "4    2014        Lavoy Allen  PF   24  IND  14   0   112  17.5  0.521  ...   \n",
       "..    ...                ...  ..  ...  ...  ..  ..   ...   ...    ...  ...   \n",
       "985  2017          Joe Young  PG   24  IND  33   0   135  11.4  0.433  ...   \n",
       "986  2017     Thaddeus Young  PF   28  IND  74  74  2237  14.9  0.562  ...   \n",
       "987  2017        Cody Zeller  PF   24  CHA  62  58  1725  16.7  0.604  ...   \n",
       "988  2017        Paul Zipser  SF   22  CHI  44  18   843   6.9  0.503  ...   \n",
       "989  2017        Ivica Zubac   C   19  LAL  38  11   609  17.0  0.547  ...   \n",
       "\n",
       "     AST  STL  BLK  TOV   PF   PTS  Register Value  Salary in $  Season End  \\\n",
       "0     43   40   57   71  203   265           10096      2184960        2015   \n",
       "1     40   23   46   63  187   328            9640       981084        2015   \n",
       "2     14    8   30   18   40    92            9721       981084        2015   \n",
       "3    178   63   68  123  147  1603            9941     16006000        2015   \n",
       "4      6    2    6    4   11    40            9947       948163        2015   \n",
       "..   ...  ...  ...  ...  ...   ...             ...          ...         ...   \n",
       "985   15    4    0    5    5    68           11566      1471382        2018   \n",
       "986  122  114   30   96  135   814           11784     14796348        2018   \n",
       "987   99   62   58   65  189   639           11404     12584270        2018   \n",
       "988   36   15   16   40   78   240           11721      1312611        2018   \n",
       "989   30   14   33   30   66   284           11520      1312611        2018   \n",
       "\n",
       "             Full Team Name  \n",
       "0     Oklahoma City Thunder  \n",
       "1      New Orleans Pelicans  \n",
       "2           New York Knicks  \n",
       "3    Portland Trail Blazers  \n",
       "4            Indiana Pacers  \n",
       "..                      ...  \n",
       "985          Indiana Pacers  \n",
       "986          Indiana Pacers  \n",
       "987       Charlotte Hornets  \n",
       "988           Chicago Bulls  \n",
       "989      Los Angeles Lakers  \n",
       "\n",
       "[990 rows x 56 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeb401e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = df.drop(['Salary in $', 'Player', 'Full Team Name'], axis = 1)\n",
    "Y = np.log(df['Salary in $'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7c43c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns = ['Pos', \"Tm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3844ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e669e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "837143ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "StandardScaler = StandardScaler()\n",
    "X_std = StandardScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "691b5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with Y std\n",
    "#Y = Y.reshape(-1,1)\n",
    "#Y_std = StandardScaler.transform(Y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6878c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_std, Y, test_size =0.33,random_state = 5 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eeb2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=0.95)\n",
    "#X_pca= sklearn_pca.fit_transform(X_train)\n",
    "X_pca = sklearn_pca.fit_transform(X_train)\n",
    "#Y_pca = sklearn_pca.transform(Y)\n",
    "Y_pca = sklearn_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70bdf163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(663, 43)\n",
      "(327, 43)\n"
     ]
    }
   ],
   "source": [
    "print(X_pca.shape)\n",
    "print(Y_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "567e54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size =0.33,random_state = 5 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6853a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "874b8515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinReg = LinearRegression()\n",
    "#LinReg.fit(X_train,Y_train)\n",
    "LinReg.fit(X_pca,Y_train)\n",
    "#Y_pred = LinReg.predict(X_test)\n",
    "Y_pred = LinReg.predict(Y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32b58a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ceb37070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average of salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b53a8575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49528538005270106\n",
      "Mean Absolute Error:  0.6565023962807386\n",
      "Mean Squared Error: 0.8677632943655472\n",
      "Mean Absolute Percentage Error:  0.045504852295322126\n",
      "RMSE: 0.9315381336078234\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "#print(\"R^2\", LinReg.score(Y_pred , Y_test))\n",
    "#print(\"R^2\", LinReg.score(X_pca , Y_test))\n",
    "print(LinReg.score(X_pca, Y_train))\n",
    "# mean absolute error which is the average of all predicted error values ,where all predicted error values are forced to be positive \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, Y_pred))\n",
    "mse = sklearn.metrics.mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Percentage Error: \", sklearn.metrics.mean_absolute_percentage_error(Y_test, Y_pred))\n",
    "#MAPE - find\n",
    "#root mean squared error is the root of the average of the squared predicted error values.\n",
    "print(\"RMSE:\", np.sqrt(mse))\n",
    "print(round(spearmanr(Y_test, Y_pred)[0],3))\n",
    "#round(spearmanr(Y_test, ypred)[0],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe1bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87af2464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Prices: $Y_i$\")\n",
    "plt.ylabel(\"Predicted salaries: $\\hat{Y}_i$\")\n",
    "plt.title(\"Salaries vs Predicted Salaries: $Y_i$ Vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "962e2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ebdf1",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf7fe2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_baseline = np.mean(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20b006a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE baseline model on Training Data: 1.1238109716675213\n",
      "RMSE baseline model on Testing Data: 1.2484509244770698\n"
     ]
    }
   ],
   "source": [
    "baseline_fit = np.mean(Y_train)\n",
    "\n",
    "# compute root mean square error (RMSE) for each model\n",
    "print(\n",
    "    'RMSE baseline model on Training Data:', np.sqrt(np.mean((Y_train - baseline_fit)**2))\n",
    ")\n",
    "\n",
    "# compute mean square error (MSE) for each model\n",
    "print(\n",
    "    'RMSE baseline model on Testing Data:', np.sqrt(np.mean((Y_test - baseline_fit)**2))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f61c7844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.01948326, 13.91136786, 16.32916662, 13.86652871, 14.08752884,\n",
       "       16.9827166 , 16.30041721, 16.26327766, 14.70033539, 14.59776691,\n",
       "       14.05528623, 13.64716173, 16.30041721, 15.31958795, 15.80748607,\n",
       "       14.92943797, 16.58847421, 16.68069037, 14.25107801, 12.89921983,\n",
       "       16.30041721, 14.09072194, 16.11809565, 16.75971919, 10.1266311 ,\n",
       "       17.01660442, 14.45157932, 15.94290858, 16.50648242, 15.8402744 ,\n",
       "       13.68767719, 16.04113458, 14.89640175, 15.90074777, 16.30041721,\n",
       "       14.55412811, 16.15124789, 15.93577417, 16.23462946, 13.81551056,\n",
       "       15.64865522, 10.08672536, 14.91412285, 14.25483524, 14.5029012 ,\n",
       "       14.75103905, 15.42494847, 16.51113825, 14.87112836, 16.08811004,\n",
       "       13.68156308, 14.91180015, 13.76134578, 15.25159458, 17.13838507,\n",
       "       12.4292162 , 16.19926136, 15.32038763, 15.16964272, 16.23911947,\n",
       "       14.85011752, 15.06827353, 15.05595482, 14.82756955, 16.84295465,\n",
       "       15.06827353, 13.15622359, 15.71092784, 16.13314307, 15.76142071,\n",
       "       15.07775218, 17.09416735, 15.84094011, 17.025275  , 14.41914323,\n",
       "       14.23704913, 15.56409788, 14.73408668, 14.22043352, 15.8949521 ,\n",
       "       16.48148951, 13.64716173, 16.63356356, 14.64327823, 13.7824707 ,\n",
       "       15.85425575, 13.72694488, 16.6855698 , 14.18603219, 14.81193581,\n",
       "       17.03438638, 16.42189711, 16.81826005, 15.46981743, 16.61887094,\n",
       "       15.06185296, 16.42695808, 16.52356076, 14.25483524, 11.22524339,\n",
       "       15.31958795, 14.96291301, 14.98476116, 14.2381867 , 10.91166443,\n",
       "       14.70033539, 14.94620274, 14.87817057, 17.20033801, 14.65680184,\n",
       "       14.23704913, 16.11809565, 14.10794134, 16.0780546 , 17.16648803,\n",
       "       15.8949521 , 11.51292546, 16.6487239 , 14.62894608, 16.45456789,\n",
       "       16.9353326 , 16.5727596 , 16.27918421, 13.90725074, 16.85380248,\n",
       "       14.22030878, 15.45225814, 14.55267462, 16.51680049, 16.81466512,\n",
       "       16.30041721, 15.87052761, 14.66080012, 16.81432453, 16.30041721,\n",
       "       16.36359613, 14.66080012, 13.68156308, 14.12217139, 15.18922588,\n",
       "       16.43934547, 13.96406848, 13.64716173, 16.30041721, 16.5595712 ,\n",
       "       17.09416735, 16.26612817, 14.66940788, 16.46875252, 16.38045992,\n",
       "       14.16156531, 14.08752884, 10.1266311 , 16.57038467, 16.59266011,\n",
       "       15.15239039, 16.91527532, 13.8647768 , 15.8949521 , 14.20171265,\n",
       "       15.00093979, 15.08356093, 16.90540321, 16.34970328, 17.07947664,\n",
       "       15.20180492, 14.4263625 , 14.58021532, 15.20180492, 15.60727003,\n",
       "       14.64901081, 15.76142071, 16.94974311, 14.20171265, 13.96365466,\n",
       "       15.60060788, 13.76134578, 14.20171265, 14.59624362, 14.29712156,\n",
       "       13.91082074, 13.64716173, 16.23587869, 16.10849915, 14.86198709,\n",
       "       15.68910006, 16.45127676, 14.03281308, 15.57875498, 15.72622467,\n",
       "       14.08752884, 16.55381026, 14.19742041, 15.76142071, 14.08752884,\n",
       "       12.83622411, 14.5464351 , 14.91861673, 14.54583791, 16.3760672 ,\n",
       "       15.42494847, 14.62644077, 15.60727003, 15.87519572, 16.63080568,\n",
       "       14.83525278, 14.6403897 , 15.51660362, 14.71209846, 15.06827353,\n",
       "       17.09416735, 14.22097567, 17.16648803, 13.61276015, 16.22527763,\n",
       "       16.30695015, 14.7276045 , 15.86066302, 14.08752884, 13.79668242,\n",
       "       15.23843622, 16.98416645, 15.80338491, 12.70076889, 14.20171265,\n",
       "       14.08752884, 13.99121024, 14.91259535, 14.81062726, 13.61276015,\n",
       "       16.83958755, 16.0760673 , 16.53680599, 14.89501512, 14.34064137,\n",
       "       14.23704913, 14.08752884, 14.91412285, 14.36030273, 16.01273514,\n",
       "       16.61279189, 15.66103257, 15.14463121, 14.85011752, 15.65128691,\n",
       "       15.73132962, 15.5432647 , 16.32425938, 15.59986938, 15.20402296,\n",
       "       16.55635058, 16.16736189, 15.0260577 , 14.20171265, 15.18930537,\n",
       "       14.9105294 , 15.95457622, 15.05614311, 14.25483524, 15.61079298,\n",
       "       15.68731273, 15.52025865, 16.61279189, 14.27901813, 15.42342431,\n",
       "       15.42494847, 15.32800135, 16.7232054 , 15.39829623, 14.08752884,\n",
       "       16.00091174, 14.08752884, 14.08752884, 16.50989095, 14.9391016 ,\n",
       "       16.46256157, 15.2211957 , 15.02175678, 13.87696683, 15.22358867,\n",
       "       14.68286059, 16.6487239 , 16.81124283, 14.52898964, 16.52436044,\n",
       "       16.99200371, 14.00619703, 14.81981217, 14.08752884, 16.41355986,\n",
       "       14.95989799, 16.62873576, 13.83108465, 15.20180492, 13.12236338,\n",
       "       14.65618079, 16.16688582, 17.17253673, 15.46896536, 14.55267462,\n",
       "       11.91839057, 16.45456789, 14.92243322, 16.73328129, 13.61276015,\n",
       "       16.01273514, 14.91412285, 14.08752884, 16.45456789, 14.01735121,\n",
       "       16.65983838, 15.46416918, 13.68156308, 11.91839057, 16.30973689,\n",
       "       15.68731273, 14.31628585, 14.56186385, 14.45094388, 15.61556883,\n",
       "       15.17900701, 16.32916662, 13.61276015, 16.13425656, 16.39335716,\n",
       "       15.1372664 , 15.8257242 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b48776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eeae66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE baseline model on Testing Data: 0.9957579031146466\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'MAE baseline model on Testing Data:', np.mean(abs(Y_test-baseline_fit))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ab07ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE baseline model on Testing Data: 6.791435040611297\n"
     ]
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "print(\n",
    "    'MAPE baseline model on Testing Data:', mape(Y_test, baseline_fit)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47535a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE baseline model on Testing Data: 0.06791435040611297\n"
     ]
    }
   ],
   "source": [
    "#https://datagy.io/mape-python/\n",
    "def mape_2(y_test, pred):\n",
    "    y_test, pred = np.array(y_test), np.array(pred)\n",
    "    mape = np.mean(np.abs((y_test - pred) / y_test))\n",
    "    return mape\n",
    "print(\n",
    "    'MAPE baseline model on Testing Data:', mape_2(Y_test, baseline_fit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddd6e2",
   "metadata": {},
   "source": [
    "# SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd60a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a076cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c39b5562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdr.fit(X_pca, Y_train)\n",
    "\n",
    "#score = sgdr.score(X_pca, Y_train)\n",
    "#print(\"R-squared:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee528127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.8800256102996424\n",
      "RMSE:  0.9380968022009468\n",
      "Mean Absolute Error:  0.6623861656408228\n",
      "Mean Squared Error: 0.8800256102996424\n",
      "Mean Absolute Percentage Error:  0.045822129885097033\n",
      "RMSE: 0.9380968022009468\n"
     ]
    }
   ],
   "source": [
    "ypred = sgdr.predict(Y_pca)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(Y_test, ypred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, ypred))\n",
    "mse = sklearn.metrics.mean_squared_error(Y_test, ypred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Percentage Error: \", sklearn.metrics.mean_absolute_percentage_error(Y_test, ypred))\n",
    "#MAPE - find\n",
    "#root mean squared error is the root of the average of the squared predicted error values.\n",
    "print(\"RMSE:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edd92f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(spearmanr(Y_test, ypred)[0],3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef3eac",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17bc2aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e463072e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2bbd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8411848296194072\n"
     ]
    }
   ],
   "source": [
    "score = reg.score(X_pca, Y_train)\n",
    "print(\"R-squared:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0485b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.8886135435210459\n",
      "RMSE:  0.9426630063395115\n",
      "Mean Absolute Error:  0.6853239056144095\n",
      "Mean Squared Error: 0.8886135435210459\n",
      "Mean Absolute Percentage Error:  0.04733204682186609\n",
      "RMSE: 0.9426630063395115\n"
     ]
    }
   ],
   "source": [
    "ypred = reg.predict(Y_pca)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(Y_test, ypred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, ypred))\n",
    "mse = sklearn.metrics.mean_squared_error(Y_test, ypred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Percentage Error: \", sklearn.metrics.mean_absolute_percentage_error(Y_test, ypred))\n",
    "#MAPE - find\n",
    "#root mean squared error is the root of the average of the squared predicted error values.\n",
    "print(\"RMSE:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f394be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "#round(spearman[0], 3))\n",
    "round(spearmanr(Y_test, ypred)[0],3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57043987",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67f3e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8411848296194072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "regr.fit(X_pca, Y_train)\n",
    "#score = regr.score(X_pca, Y_train)\n",
    "print(\"R-squared:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3cafc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.8358447161660162\n",
      "RMSE:  0.9142454354089039\n",
      "Mean Absolute Error:  0.6694918395333495\n",
      "Mean Squared Error: 0.8358447161660162\n",
      "Mean Absolute Percentage Error:  0.046158166176135995\n",
      "RMSE: 0.9142454354089039\n"
     ]
    }
   ],
   "source": [
    "ypred = regr.predict(Y_pca)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(Y_test, ypred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, ypred))\n",
    "mse = sklearn.metrics.mean_squared_error(Y_test, ypred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Percentage Error: \", sklearn.metrics.mean_absolute_percentage_error(Y_test, ypred))\n",
    "#MAPE - find\n",
    "#root mean squared error is the root of the average of the squared predicted error values.\n",
    "print(\"RMSE:\", np.sqrt(mse))\n",
    "#print(regr.score(ypred, np.array(Y_test).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99b63983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(spearmanr(Y_test, ypred)[0],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181afad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the one with the lowest RMSE and do hyper parameter tuning on it\n",
    "#GradientBoostingRegressor has highest R2 will do hyperparameter tuning on this classifier using RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8883dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_error, max_iter=1000;, score=-0.155 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_error, max_iter=1000;, score=0.057 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_error, max_iter=1000;, score=0.220 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_error, max_iter=1000;, score=-0.055 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_error, max_iter=1000;, score=-0.378 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_error, max_iter=2000;, score=0.136 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_error, max_iter=2000;, score=0.310 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_error, max_iter=2000;, score=0.055 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_error, max_iter=2000;, score=-0.279 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_error, max_iter=2000;, score=0.045 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_error, max_iter=3000;, score=0.207 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_error, max_iter=3000;, score=-0.423 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_error, max_iter=3000;, score=-0.016 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_error, max_iter=3000;, score=0.107 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_error, max_iter=3000;, score=-0.082 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_error, max_iter=5000;, score=0.084 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_error, max_iter=5000;, score=0.191 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_error, max_iter=5000;, score=0.051 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_error, max_iter=5000;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_error, max_iter=5000;, score=0.245 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=huber, max_iter=1000;, score=0.348 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=huber, max_iter=1000;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=huber, max_iter=1000;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=huber, max_iter=1000;, score=0.450 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=huber, max_iter=1000;, score=0.316 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=huber, max_iter=2000;, score=0.347 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=huber, max_iter=2000;, score=0.399 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=huber, max_iter=2000;, score=0.454 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=huber, max_iter=2000;, score=0.455 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=huber, max_iter=2000;, score=0.297 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=huber, max_iter=3000;, score=0.337 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=huber, max_iter=3000;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=huber, max_iter=3000;, score=0.438 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=huber, max_iter=3000;, score=0.441 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=huber, max_iter=3000;, score=0.308 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=huber, max_iter=5000;, score=0.344 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=huber, max_iter=5000;, score=0.387 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=huber, max_iter=5000;, score=0.457 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=huber, max_iter=5000;, score=0.455 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=huber, max_iter=5000;, score=0.320 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=1000;, score=0.087 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=1000;, score=-0.072 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=1000;, score=0.132 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=1000;, score=0.098 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=1000;, score=0.127 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=2000;, score=0.139 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=2000;, score=0.208 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=2000;, score=-0.032 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=2000;, score=0.237 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=2000;, score=-0.111 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=3000;, score=0.070 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=3000;, score=0.044 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=3000;, score=0.208 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=3000;, score=0.118 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=3000;, score=-0.255 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=5000;, score=0.216 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=5000;, score=-0.007 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=5000;, score=-0.099 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=5000;, score=0.234 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=epsilon_insensitive, max_iter=5000;, score=0.085 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000;, score=-893310.523 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000;, score=-1929.609 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000;, score=-112.265 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000;, score=-48334.172 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000;, score=-160.955 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000;, score=-3790973.310 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000;, score=-16.759 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000;, score=-4.689 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000;, score=-37.108 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000;, score=-17.883 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=3000;, score=-5.984 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=3000;, score=-390.175 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=3000;, score=-7.750 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=3000;, score=-96784.711 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=3000;, score=-43.516 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=5000;, score=-38946.012 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=5000;, score=-47.046 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=5000;, score=-15.527 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=5000;, score=-1751.842 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=5000;, score=-195.999 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_error, max_iter=1000;, score=-24260642783201932343246848.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_error, max_iter=1000;, score=-8904737828673894228164608.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_error, max_iter=1000;, score=-36257768192058313249128448.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_error, max_iter=1000;, score=-22524874176735834040958976.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_error, max_iter=1000;, score=-9185674805056457813262336.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_error, max_iter=2000;, score=-11985482005663789833256960.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_error, max_iter=2000;, score=-30647108096598839018913792.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_error, max_iter=2000;, score=-42668073038003072973930496.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_error, max_iter=2000;, score=-8964253090753314881011712.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_error, max_iter=2000;, score=-16707463011409526368763904.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_error, max_iter=3000;, score=-17902226940784547047931904.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_error, max_iter=3000;, score=-11430628094829459150995456.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_error, max_iter=3000;, score=-41262939062783850781343744.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_error, max_iter=3000;, score=-8380336285889442063843328.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_error, max_iter=3000;, score=-27732998849085368604557312.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_error, max_iter=5000;, score=-21530481060772079466446848.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_error, max_iter=5000;, score=-16649127640025299798720512.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_error, max_iter=5000;, score=-30775405804968080712925184.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_error, max_iter=5000;, score=-13219532931930815083839488.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_error, max_iter=5000;, score=-14071712441317677449871360.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=huber, max_iter=1000;, score=-0.932 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=huber, max_iter=1000;, score=-0.452 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=huber, max_iter=1000;, score=-0.505 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=huber, max_iter=1000;, score=-1.449 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=huber, max_iter=1000;, score=-0.750 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=huber, max_iter=2000;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=huber, max_iter=2000;, score=-0.419 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=huber, max_iter=2000;, score=-1.198 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=huber, max_iter=2000;, score=-2.200 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=huber, max_iter=2000;, score=-0.235 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=huber, max_iter=3000;, score=-0.130 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=huber, max_iter=3000;, score=-1.414 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=huber, max_iter=3000;, score=-1.919 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=huber, max_iter=3000;, score=-1.079 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=huber, max_iter=3000;, score=-1.626 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=huber, max_iter=5000;, score=-0.422 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=huber, max_iter=5000;, score=-0.317 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=huber, max_iter=5000;, score=-0.396 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=huber, max_iter=5000;, score=-1.806 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=huber, max_iter=5000;, score=-0.330 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000;, score=-6.867 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000;, score=-9.004 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000;, score=-10.787 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000;, score=-9.709 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000;, score=-12.502 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000;, score=-16.180 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000;, score=-20.732 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000;, score=-3.177 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000;, score=-49.525 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000;, score=-14.676 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=3000;, score=-17.361 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=3000;, score=-10.627 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=3000;, score=-25.547 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=3000;, score=-10.413 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=3000;, score=-14.794 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=5000;, score=-11.655 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=5000;, score=-17.302 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=5000;, score=-14.389 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=5000;, score=-20.662 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=epsilon_insensitive, max_iter=5000;, score=-14.456 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000;, score=-12621051495065968367894528.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000;, score=-10971872570342857550856192.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000;, score=-13526548272360571115929600.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000;, score=-7354383605080284347760640.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000;, score=-12340910487938578337759232.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000;, score=-22852738924811465128935424.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000;, score=-17445400325644357143101440.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000;, score=-5311937165280545211416576.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000;, score=-8154051060697450416177152.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000;, score=-132113524798019419492057088.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=3000;, score=-15963263556050720447791104.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=3000;, score=-49736943987137822284840960.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=3000;, score=-22736596634627113905815552.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=3000;, score=-18788240243662196234518528.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=3000;, score=-19086893670576552583102464.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=5000;, score=-15806546199192131262742528.000 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=5000;, score=-15129009393299977882566656.000 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=5000;, score=-32707858739182344412856320.000 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=5000;, score=-14812800712634541386235904.000 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=5000;, score=-31050651011209934879588352.000 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_error, max_iter=1000;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_error, max_iter=1000;, score=0.420 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_error, max_iter=1000;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_error, max_iter=1000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_error, max_iter=1000;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_error, max_iter=2000;, score=0.367 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_error, max_iter=2000;, score=0.408 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_error, max_iter=2000;, score=0.411 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_error, max_iter=2000;, score=0.443 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_error, max_iter=2000;, score=0.367 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_error, max_iter=3000;, score=0.368 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_error, max_iter=3000;, score=0.393 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_error, max_iter=3000;, score=0.409 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_error, max_iter=3000;, score=0.449 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_error, max_iter=3000;, score=0.362 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_error, max_iter=5000;, score=0.362 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_error, max_iter=5000;, score=0.408 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_error, max_iter=5000;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_error, max_iter=5000;, score=0.473 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_error, max_iter=5000;, score=0.315 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=huber, max_iter=1000;, score=-2.828 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=huber, max_iter=1000;, score=-1.936 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=huber, max_iter=1000;, score=-1.150 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=huber, max_iter=1000;, score=-0.959 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=huber, max_iter=1000;, score=-4.262 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=huber, max_iter=2000;, score=-2.826 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=huber, max_iter=2000;, score=-1.901 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=huber, max_iter=2000;, score=-1.192 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=huber, max_iter=2000;, score=-0.948 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=huber, max_iter=2000;, score=-4.260 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=huber, max_iter=3000;, score=-2.881 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=huber, max_iter=3000;, score=-1.946 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=huber, max_iter=3000;, score=-1.163 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=huber, max_iter=3000;, score=-0.958 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=huber, max_iter=3000;, score=-4.262 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=huber, max_iter=5000;, score=-2.774 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=huber, max_iter=5000;, score=-1.906 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=huber, max_iter=5000;, score=-1.193 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=huber, max_iter=5000;, score=-0.956 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=huber, max_iter=5000;, score=-4.267 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000;, score=0.355 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000;, score=0.394 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000;, score=0.451 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000;, score=0.454 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000;, score=0.324 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000;, score=0.361 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000;, score=0.431 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000;, score=0.439 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000;, score=0.311 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=3000;, score=0.364 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=3000;, score=0.368 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=3000;, score=0.428 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=3000;, score=0.453 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=3000;, score=0.306 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=5000;, score=0.356 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=5000;, score=0.385 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=5000;, score=0.457 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=5000;, score=0.452 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=epsilon_insensitive, max_iter=5000;, score=0.316 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.361 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.394 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.374 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.467 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.363 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.363 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.405 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.365 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.472 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.370 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.328 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.385 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.430 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.428 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.354 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.353 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.366 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.326 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.468 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.383 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_error, max_iter=1000;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_error, max_iter=1000;, score=0.414 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_error, max_iter=1000;, score=0.407 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_error, max_iter=1000;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_error, max_iter=1000;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_error, max_iter=2000;, score=0.371 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_error, max_iter=2000;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_error, max_iter=2000;, score=0.412 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_error, max_iter=2000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_error, max_iter=2000;, score=0.372 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_error, max_iter=3000;, score=0.373 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_error, max_iter=3000;, score=0.410 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_error, max_iter=3000;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_error, max_iter=3000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_error, max_iter=3000;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_error, max_iter=5000;, score=0.371 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_error, max_iter=5000;, score=0.413 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_error, max_iter=5000;, score=0.411 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_error, max_iter=5000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_error, max_iter=5000;, score=0.372 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=huber, max_iter=1000;, score=0.352 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=huber, max_iter=1000;, score=0.390 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=huber, max_iter=1000;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=huber, max_iter=1000;, score=0.451 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=huber, max_iter=1000;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=huber, max_iter=2000;, score=0.355 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=huber, max_iter=2000;, score=0.392 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=huber, max_iter=2000;, score=0.453 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=huber, max_iter=2000;, score=0.448 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=huber, max_iter=2000;, score=0.320 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=huber, max_iter=3000;, score=0.355 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=huber, max_iter=3000;, score=0.392 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=huber, max_iter=3000;, score=0.442 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=huber, max_iter=3000;, score=0.448 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=huber, max_iter=3000;, score=0.316 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=huber, max_iter=5000;, score=0.350 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=huber, max_iter=5000;, score=0.392 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=huber, max_iter=5000;, score=0.443 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=huber, max_iter=5000;, score=0.448 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=huber, max_iter=5000;, score=0.329 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000;, score=0.353 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000;, score=0.383 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000;, score=0.432 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000;, score=0.450 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000;, score=0.323 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000;, score=0.356 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000;, score=0.380 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000;, score=0.436 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000;, score=0.451 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=3000;, score=0.353 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=3000;, score=0.379 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=3000;, score=0.437 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=3000;, score=0.450 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=3000;, score=0.319 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=5000;, score=0.354 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=5000;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=5000;, score=0.435 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=5000;, score=0.448 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=epsilon_insensitive, max_iter=5000;, score=0.314 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.410 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.406 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000;, score=0.378 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.371 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.412 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.407 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000;, score=0.377 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.410 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.402 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=3000;, score=0.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.371 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.408 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.406 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=5000;, score=0.379 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SGDRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;epsilon_insensitive&#x27;,\n",
       "                                  &#x27;squared_epsilon_insensitive&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [1000, 2000, 3000, 5000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SGDRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;epsilon_insensitive&#x27;,\n",
       "                                  &#x27;squared_epsilon_insensitive&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [1000, 2000, 3000, 5000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SGDRegressor(),\n",
       "             param_grid={'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'loss': ['squared_error', 'huber',\n",
       "                                  'epsilon_insensitive',\n",
       "                                  'squared_epsilon_insensitive'],\n",
       "                         'max_iter': [1000, 2000, 3000, 5000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "  'learning_rate': ['constant', 'optimal', 'invscaling','adaptive'], \n",
    "  'loss': ['squared_error', 'huber', 'epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "    'max_iter':[1000,2000,3000,5000]\n",
    "}\n",
    "grid = GridSearchCV(SGDRegressor(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_pca,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6503209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 'invscaling', 'loss': 'squared_error', 'max_iter': 1000}\n",
      "SGDRegressor()\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "\n",
    "# Find the best estimator\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "821d48c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.8875696887986074\n",
      "RMSE:  0.9421091703187097\n",
      "Mean Absolute Error:  0.6665862894414627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.746"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pred = grid.predict(Y_pca)\n",
    "mse = mean_squared_error(Y_test, grid_pred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, grid_pred))\n",
    "round(spearmanr(Y_test, grid_pred)[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have the lowest RMSE now from this classifier I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20b2a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END ...........n_jobs=1, positive=True;, score=0.315 total time=   0.0s\n",
      "[CV 2/5] END ...........n_jobs=1, positive=True;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ...........n_jobs=1, positive=True;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END ...........n_jobs=1, positive=True;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END ...........n_jobs=1, positive=True;, score=0.285 total time=   0.0s\n",
      "[CV 1/5] END ..........n_jobs=1, positive=False;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END ..........n_jobs=1, positive=False;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ..........n_jobs=1, positive=False;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END ..........n_jobs=1, positive=False;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........n_jobs=1, positive=False;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END ...........n_jobs=2, positive=True;, score=0.315 total time=   0.0s\n",
      "[CV 2/5] END ...........n_jobs=2, positive=True;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ...........n_jobs=2, positive=True;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END ...........n_jobs=2, positive=True;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END ...........n_jobs=2, positive=True;, score=0.285 total time=   0.0s\n",
      "[CV 1/5] END ..........n_jobs=2, positive=False;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END ..........n_jobs=2, positive=False;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ..........n_jobs=2, positive=False;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END ..........n_jobs=2, positive=False;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........n_jobs=2, positive=False;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END ...........n_jobs=3, positive=True;, score=0.315 total time=   0.0s\n",
      "[CV 2/5] END ...........n_jobs=3, positive=True;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ...........n_jobs=3, positive=True;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END ...........n_jobs=3, positive=True;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END ...........n_jobs=3, positive=True;, score=0.285 total time=   0.0s\n",
      "[CV 1/5] END ..........n_jobs=3, positive=False;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END ..........n_jobs=3, positive=False;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ..........n_jobs=3, positive=False;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END ..........n_jobs=3, positive=False;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........n_jobs=3, positive=False;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END ...........n_jobs=5, positive=True;, score=0.315 total time=   0.0s\n",
      "[CV 2/5] END ...........n_jobs=5, positive=True;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ...........n_jobs=5, positive=True;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END ...........n_jobs=5, positive=True;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END ...........n_jobs=5, positive=True;, score=0.285 total time=   0.0s\n",
      "[CV 1/5] END ..........n_jobs=5, positive=False;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END ..........n_jobs=5, positive=False;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ..........n_jobs=5, positive=False;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END ..........n_jobs=5, positive=False;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........n_jobs=5, positive=False;, score=0.375 total time=   0.0s\n",
      "[CV 1/5] END ...........n_jobs=6, positive=True;, score=0.315 total time=   0.0s\n",
      "[CV 2/5] END ...........n_jobs=6, positive=True;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ...........n_jobs=6, positive=True;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END ...........n_jobs=6, positive=True;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END ...........n_jobs=6, positive=True;, score=0.285 total time=   0.0s\n",
      "[CV 1/5] END ..........n_jobs=6, positive=False;, score=0.372 total time=   0.0s\n",
      "[CV 2/5] END ..........n_jobs=6, positive=False;, score=0.411 total time=   0.0s\n",
      "[CV 3/5] END ..........n_jobs=6, positive=False;, score=0.408 total time=   0.0s\n",
      "[CV 4/5] END ..........n_jobs=6, positive=False;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........n_jobs=6, positive=False;, score=0.375 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LinearRegression(),\n",
       "             param_grid={&#x27;n_jobs&#x27;: [1, 2, 3, 5, 6], &#x27;positive&#x27;: [True, False]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LinearRegression(),\n",
       "             param_grid={&#x27;n_jobs&#x27;: [1, 2, 3, 5, 6], &#x27;positive&#x27;: [True, False]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LinearRegression(),\n",
       "             param_grid={'n_jobs': [1, 2, 3, 5, 6], 'positive': [True, False]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "  'n_jobs': [1,2,3,5,6], \n",
    "  'positive': [True, False]#,\n",
    "    #'max_iter':[1000,2000,3000,5000]\n",
    "}\n",
    "grid = GridSearchCV(LinearRegression(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_pca,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c774b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.8677632943655472\n",
      "RMSE:  0.9315381336078234\n",
      "Mean Absolute Error:  0.6565023962807386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pred = grid.predict(Y_pca)\n",
    "mse = mean_squared_error(Y_test, grid_pred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, grid_pred))\n",
    "round(spearmanr(Y_test, grid_pred)[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "163112a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.375 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.397 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.428 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.371 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.393 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.355 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.386 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.451 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.344 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.393 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.373 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.400 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.431 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.356 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.389 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.367 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.417 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.442 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.365 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.378 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.375 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.411 total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.443 total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.359 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.373 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.362 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.379 total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.445 total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.365 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.376 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.369 total time=   1.0s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.402 total time=   1.0s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.444 total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.363 total time=   1.0s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.372 total time=   1.0s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.363 total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.400 total time=   0.9s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.456 total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.374 total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.389 total time=   0.9s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.367 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.397 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.451 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.362 total time=   1.3s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.386 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.360 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.398 total time=   1.1s\n",
      "[CV 3/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.455 total time=   1.1s\n",
      "[CV 4/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.368 total time=   1.1s\n",
      "[CV 5/5] END criterion=squared_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.382 total time=   1.1s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.348 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.387 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.433 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.360 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.360 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.331 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.382 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.441 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.346 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.378 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.345 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.372 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.427 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.341 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.373 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.343 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.375 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.436 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.340 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.368 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.364 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.371 total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.434 total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.355 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.367 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.364 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.373 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.423 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.351 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.362 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.360 total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.386 total time=   0.9s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.433 total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.351 total time=   1.0s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.377 total time=   1.0s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.353 total time=   0.9s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.379 total time=   0.9s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.432 total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.357 total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.382 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.347 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.386 total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.432 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.342 total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.378 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.357 total time=   1.0s\n",
      "[CV 2/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.370 total time=   1.0s\n",
      "[CV 3/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.431 total time=   1.0s\n",
      "[CV 4/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.351 total time=   1.0s\n",
      "[CV 5/5] END criterion=squared_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.371 total time=   1.0s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=True;, score=0.384 total time=   0.7s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=True;, score=0.480 total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=True;, score=0.486 total time=   0.7s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=True;, score=0.417 total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=True;, score=0.365 total time=   0.7s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=False;, score=0.385 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=False;, score=0.488 total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=False;, score=0.521 total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=False;, score=0.435 total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=100, oob_score=False;, score=0.364 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=True;, score=0.384 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=True;, score=0.465 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=True;, score=0.499 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=True;, score=0.443 total time=   1.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=True;, score=0.373 total time=   1.4s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=False;, score=0.390 total time=   1.3s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=False;, score=0.481 total time=   1.3s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=False;, score=0.502 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=False;, score=0.430 total time=   1.3s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=200, oob_score=False;, score=0.376 total time=   1.3s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=True;, score=0.391 total time=   2.0s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=True;, score=0.486 total time=   2.0s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=True;, score=0.504 total time=   1.9s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=True;, score=0.434 total time=   2.0s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=True;, score=0.373 total time=   2.0s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=False;, score=0.386 total time=   1.9s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=False;, score=0.475 total time=   2.2s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=False;, score=0.511 total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=False;, score=0.430 total time=   2.1s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=300, oob_score=False;, score=0.383 total time=   2.1s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=True;, score=0.382 total time=   3.4s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=True;, score=0.485 total time=   3.3s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=True;, score=0.495 total time=   3.3s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=True;, score=0.433 total time=   3.4s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=True;, score=0.379 total time=   3.4s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=False;, score=0.399 total time=   3.3s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=False;, score=0.476 total time=   3.3s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=False;, score=0.512 total time=   3.1s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=False;, score=0.437 total time=   3.2s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=500, oob_score=False;, score=0.391 total time=   3.2s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=True;, score=0.392 total time=   4.1s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=True;, score=0.483 total time=   4.1s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=True;, score=0.501 total time=   4.0s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=True;, score=0.438 total time=   3.9s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=True;, score=0.389 total time=   4.0s\n",
      "[CV 1/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=False;, score=0.396 total time=   3.9s\n",
      "[CV 2/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=False;, score=0.482 total time=   3.9s\n",
      "[CV 3/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=False;, score=0.509 total time=   3.8s\n",
      "[CV 4/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=False;, score=0.434 total time=   3.9s\n",
      "[CV 5/5] END criterion=squared_error, max_features=None, n_estimators=600, oob_score=False;, score=0.381 total time=   3.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.337 total time=   1.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.380 total time=   1.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.421 total time=   1.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.317 total time=   1.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.345 total time=   1.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.369 total time=   1.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.378 total time=   1.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.440 total time=   1.0s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.357 total time=   1.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.324 total time=   1.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.346 total time=   2.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.390 total time=   2.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.429 total time=   2.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.338 total time=   2.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.346 total time=   2.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.352 total time=   2.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.388 total time=   2.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.436 total time=   2.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.348 total time=   2.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.337 total time=   2.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.345 total time=   3.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.385 total time=   3.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.450 total time=   3.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.341 total time=   3.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.346 total time=   3.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.356 total time=   3.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.381 total time=   3.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.454 total time=   3.0s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.333 total time=   3.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.348 total time=   3.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.358 total time=   5.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.381 total time=   5.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.448 total time=   5.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.341 total time=   5.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.349 total time=   5.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.353 total time=   5.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.392 total time=   5.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.452 total time=   5.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.352 total time=   4.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.351 total time=   4.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.347 total time=   6.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.394 total time=   6.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.454 total time=   6.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.352 total time=   6.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.371 total time=   6.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.351 total time=   6.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.390 total time=   6.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.455 total time=   6.0s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.348 total time=   5.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.340 total time=   5.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.339 total time=   0.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.349 total time=   0.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.446 total time=   0.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.298 total time=   0.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=True;, score=0.335 total time=   0.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.324 total time=   0.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.377 total time=   0.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.418 total time=   0.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.316 total time=   0.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=100, oob_score=False;, score=0.353 total time=   0.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.331 total time=   1.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.370 total time=   1.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.435 total time=   1.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.353 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=True;, score=0.351 total time=   1.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.322 total time=   1.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.357 total time=   1.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.438 total time=   1.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.328 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=200, oob_score=False;, score=0.347 total time=   1.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.328 total time=   2.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.367 total time=   2.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.431 total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.335 total time=   2.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=True;, score=0.341 total time=   2.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.338 total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.365 total time=   2.7s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.440 total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.325 total time=   2.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=300, oob_score=False;, score=0.348 total time=   2.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.347 total time=   4.6s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.362 total time=   4.7s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.432 total time=   4.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.325 total time=   4.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=True;, score=0.336 total time=   4.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.331 total time=   4.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.379 total time=   4.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.437 total time=   4.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.318 total time=   4.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=500, oob_score=False;, score=0.336 total time=   5.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.328 total time=   6.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.370 total time=   5.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.431 total time=   5.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.338 total time=   5.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=True;, score=0.340 total time=   5.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.346 total time=   5.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.374 total time=   5.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.434 total time=   5.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.331 total time=   5.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=log2, n_estimators=600, oob_score=False;, score=0.347 total time=   5.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=True;, score=0.366 total time=   5.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=True;, score=0.449 total time=   5.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=True;, score=0.479 total time=   5.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=True;, score=0.440 total time=   5.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=True;, score=0.359 total time=   5.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=False;, score=0.352 total time=   5.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=False;, score=0.472 total time=   5.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=False;, score=0.474 total time=   5.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=False;, score=0.419 total time=   5.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=100, oob_score=False;, score=0.355 total time=   5.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=True;, score=0.351 total time=  10.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=True;, score=0.453 total time=  10.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=True;, score=0.494 total time=  10.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=True;, score=0.435 total time=  10.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=True;, score=0.338 total time=  10.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=False;, score=0.369 total time=  10.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=False;, score=0.456 total time=  10.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=False;, score=0.489 total time=  11.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=False;, score=0.424 total time=  11.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=200, oob_score=False;, score=0.343 total time=  11.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=True;, score=0.354 total time=  17.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=True;, score=0.476 total time=  16.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=True;, score=0.490 total time=  15.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=True;, score=0.434 total time=  15.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=True;, score=0.332 total time=  16.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=False;, score=0.356 total time=  17.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=False;, score=0.465 total time=  16.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=False;, score=0.487 total time=  16.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=False;, score=0.421 total time=  15.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=300, oob_score=False;, score=0.347 total time=  16.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=True;, score=0.371 total time=  27.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=True;, score=0.467 total time=  26.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=True;, score=0.481 total time=  27.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=True;, score=0.433 total time=  28.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=True;, score=0.338 total time=  28.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=False;, score=0.369 total time=  27.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=False;, score=0.460 total time=  27.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=False;, score=0.493 total time=  26.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=False;, score=0.432 total time=  27.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=500, oob_score=False;, score=0.326 total time=  25.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=True;, score=0.372 total time=  30.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=True;, score=0.469 total time=  30.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=True;, score=0.499 total time=  30.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=True;, score=0.432 total time=  30.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=True;, score=0.344 total time=  30.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=False;, score=0.360 total time=  30.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=False;, score=0.461 total time=  30.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=False;, score=0.486 total time=  30.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=False;, score=0.430 total time=  29.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_features=None, n_estimators=600, oob_score=False;, score=0.335 total time=  30.6s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.390 total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.413 total time=   0.3s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.449 total time=   0.3s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.331 total time=   0.3s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=True;, score=0.370 total time=   0.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.394 total time=   0.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.405 total time=   0.2s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.443 total time=   0.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.382 total time=   0.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=100, oob_score=False;, score=0.387 total time=   0.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.367 total time=   0.5s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.397 total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.454 total time=   0.5s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.358 total time=   0.5s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=True;, score=0.366 total time=   0.5s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.363 total time=   0.5s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.381 total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.441 total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.354 total time=   0.5s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=200, oob_score=False;, score=0.360 total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.362 total time=   0.7s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.398 total time=   0.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.439 total time=   0.7s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.383 total time=   0.7s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=True;, score=0.396 total time=   0.7s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.352 total time=   0.7s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.406 total time=   0.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.438 total time=   0.7s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.375 total time=   0.7s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=300, oob_score=False;, score=0.384 total time=   0.7s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.368 total time=   1.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.399 total time=   1.2s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.446 total time=   1.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.370 total time=   1.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=True;, score=0.391 total time=   1.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.356 total time=   1.1s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.399 total time=   1.1s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.456 total time=   1.1s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.363 total time=   1.1s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=500, oob_score=False;, score=0.394 total time=   1.1s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.364 total time=   1.5s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.409 total time=   1.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.462 total time=   1.5s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.375 total time=   1.5s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=True;, score=0.391 total time=   1.5s\n",
      "[CV 1/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.368 total time=   1.3s\n",
      "[CV 2/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.415 total time=   1.3s\n",
      "[CV 3/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.455 total time=   1.4s\n",
      "[CV 4/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.368 total time=   1.4s\n",
      "[CV 5/5] END criterion=poisson, max_features=sqrt, n_estimators=600, oob_score=False;, score=0.389 total time=   1.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=True;, score=0.311 total time=   0.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=True;, score=0.357 total time=   0.2s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=True;, score=0.424 total time=   0.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=True;, score=0.381 total time=   0.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=True;, score=0.358 total time=   0.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=False;, score=0.357 total time=   0.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=False;, score=0.390 total time=   0.2s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=False;, score=0.464 total time=   0.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=False;, score=0.351 total time=   0.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=100, oob_score=False;, score=0.393 total time=   0.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=True;, score=0.357 total time=   0.5s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=True;, score=0.390 total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=True;, score=0.419 total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=True;, score=0.360 total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=True;, score=0.363 total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=False;, score=0.350 total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=False;, score=0.368 total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=False;, score=0.418 total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=False;, score=0.355 total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=200, oob_score=False;, score=0.369 total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=True;, score=0.352 total time=   0.7s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=True;, score=0.391 total time=   0.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=True;, score=0.454 total time=   0.7s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=True;, score=0.360 total time=   0.7s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=True;, score=0.369 total time=   0.7s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=False;, score=0.356 total time=   0.6s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=False;, score=0.383 total time=   0.6s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=False;, score=0.437 total time=   0.6s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=False;, score=0.340 total time=   0.6s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=300, oob_score=False;, score=0.390 total time=   0.6s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=True;, score=0.351 total time=   1.1s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=True;, score=0.378 total time=   1.1s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=True;, score=0.435 total time=   1.1s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=True;, score=0.363 total time=   1.1s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=True;, score=0.379 total time=   1.1s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=False;, score=0.352 total time=   1.0s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=False;, score=0.378 total time=   1.0s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=False;, score=0.429 total time=   1.0s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=False;, score=0.343 total time=   1.0s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=500, oob_score=False;, score=0.374 total time=   1.0s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=True;, score=0.357 total time=   1.4s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=True;, score=0.377 total time=   1.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=True;, score=0.431 total time=   1.3s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=True;, score=0.348 total time=   1.3s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=True;, score=0.377 total time=   1.3s\n",
      "[CV 1/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=False;, score=0.353 total time=   1.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=False;, score=0.390 total time=   1.2s\n",
      "[CV 3/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=False;, score=0.441 total time=   1.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=False;, score=0.337 total time=   1.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=log2, n_estimators=600, oob_score=False;, score=0.371 total time=   1.2s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=True;, score=0.392 total time=   0.9s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=True;, score=0.463 total time=   0.9s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=True;, score=0.498 total time=   0.9s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=True;, score=0.452 total time=   0.9s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=True;, score=0.363 total time=   0.9s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=False;, score=0.387 total time=   0.9s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=False;, score=0.475 total time=   0.9s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=False;, score=0.475 total time=   0.9s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=False;, score=0.430 total time=   0.9s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=100, oob_score=False;, score=0.386 total time=   0.9s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=True;, score=0.403 total time=   1.7s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=True;, score=0.468 total time=   1.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=True;, score=0.498 total time=   1.7s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=True;, score=0.415 total time=   1.7s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=True;, score=0.380 total time=   1.7s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=False;, score=0.387 total time=   1.7s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=False;, score=0.477 total time=   1.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=False;, score=0.485 total time=   1.7s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=False;, score=0.428 total time=   1.8s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=200, oob_score=False;, score=0.380 total time=   1.7s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=True;, score=0.387 total time=   2.6s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=True;, score=0.485 total time=   2.7s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=True;, score=0.494 total time=   2.6s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=True;, score=0.416 total time=   2.6s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=True;, score=0.374 total time=   2.6s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=False;, score=0.378 total time=   2.5s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=False;, score=0.478 total time=   2.6s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=False;, score=0.486 total time=   2.5s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=False;, score=0.434 total time=   2.5s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=300, oob_score=False;, score=0.385 total time=   2.5s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=True;, score=0.397 total time=   4.3s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=True;, score=0.477 total time=   4.4s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=True;, score=0.506 total time=   4.3s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=True;, score=0.423 total time=   4.7s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=True;, score=0.384 total time=   4.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=False;, score=0.393 total time=   4.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=False;, score=0.477 total time=   4.3s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=False;, score=0.500 total time=   4.2s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=False;, score=0.431 total time=  21.8s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=500, oob_score=False;, score=0.386 total time=   4.5s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=True;, score=0.397 total time=   5.3s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=True;, score=0.489 total time=   5.3s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=True;, score=0.499 total time=   5.1s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=True;, score=0.427 total time=   5.2s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=True;, score=0.383 total time=   5.4s\n",
      "[CV 1/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=False;, score=0.392 total time=   5.2s\n",
      "[CV 2/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=False;, score=0.489 total time=   5.1s\n",
      "[CV 3/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=False;, score=0.499 total time=   5.0s\n",
      "[CV 4/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=False;, score=0.426 total time=   5.1s\n",
      "[CV 5/5] END criterion=poisson, max_features=None, n_estimators=600, oob_score=False;, score=0.380 total time=   5.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 500, 600],\n",
       "                         &#x27;oob_score&#x27;: [True, False]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 500, 600],\n",
       "                         &#x27;oob_score&#x27;: [True, False]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={'criterion': ['squared_error', 'absolute_error',\n",
       "                                       'poisson'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [100, 200, 300, 500, 600],\n",
       "                         'oob_score': [True, False]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "  'n_estimators': [100,200,300,500,600], \n",
    "  'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "   'oob_score':[True, False]#,\n",
    "    #'max_iter':[1000,2000,3000,5000]\n",
    "}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_pca,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0353aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.817245355559677\n",
      "RMSE:  0.9040162363363154\n",
      "Mean Absolute Error:  0.6499397824271804\n",
      "Mean Absolute Percentage Error:  0.046158166176135995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.739"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pred = grid.predict(Y_pca)\n",
    "mse = mean_squared_error(Y_test, grid_pred)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0)) \n",
    "print(\"Mean Absolute Error: \", sklearn.metrics.mean_absolute_error(Y_test, grid_pred))\n",
    "print(\"Mean Absolute Percentage Error: \", sklearn.metrics.mean_absolute_percentage_error(Y_test, ypred))\n",
    "\n",
    "round(spearmanr(Y_test, grid_pred)[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e19fb0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'squared_error',\n",
       " 'max_features': None,\n",
       " 'n_estimators': 500,\n",
       " 'oob_score': False}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5047d941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4428656757447971"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1b24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
